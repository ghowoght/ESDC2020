#!/usr/bin/env python3
# #-*- coding: UTF-8 -*- 

import pyaudio
import wave
import cv2

import SpeechRecognizer
# import SemanticAnalyzer
import SpeechSynthesis

import time
import threading
import numpy as np 
from matplotlib import pyplot as plt
import struct as st
from VAD import VAD

import socket
import time
import numpy as np
import subprocess

def send_cmd(cmd):
    ## ÂèëÈÄÅÊåá‰ª§ÁªôÊú∫Âô®‰∫∫
    host = '192.168.3.7' # ip
    port = 8000 # Á´ØÂè£Âè∑
    address = (host, port)
    tcpClient = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # ÂàõÂª∫‰∏Ä‰∏™Â•óÊé•Â≠ó
    tcpClient.connect(address) # ËøûÊé•Êú∫Âô®‰∫∫

    tcpClient.send(bytes(cmd, encoding="utf-8")) # ÂèëÈÄÅÊåá‰ª§
    data = tcpClient.recv(1024) #Êé•Êî∂ÂèçÈ¶àÂÄº
    if data.decode() == b"ok":
        pass
    tcpClient.close() # ÂÖ≥Èó≠ËøûÊé•

STATUS_WAITING_WAKE_UP = 0
STATUS_WAITING_FOR_COMMAND = 1
STATUS_WAITING_FOR_CONFIRM = 2
STATUS_WORKING = 3

WAKE_UP_WORDS = "Â∞è‰∫îÂ∞è‰∫î"
wake_up_words_list = ["Â∞è‰∫îÂ∞è‰∫î", "ÊÉ≥ÊàëÊÉ≥Êàë", "‰∏ãÂçà‰∏ãÂçà", "Â∞èÊ≠¶Â∞èÊ≠¶", "Á¨ëÊàëÁ¨ëÊàë"]

hero_cmds = ["mapping_semantic", "navigation", "nav_semantic", "stop"]
aibox_cmds = ["mapping_semantic", "navigation", "nav_semantic", "stop", "return_origin"]

servers = ["ÊêúÂØªÁõÆÊ†á", "ÊûÑÂª∫ËØ≠‰πâÂú∞Âõæ", "ÊûÑÂª∫Âú∞Âõæ", "ËøîÂõûÂéüÁÇπ", "ËøîÂõûËµ∑ÁÇπ", "ÂÅúÊ≠¢ÈîÆÂõæ", 
                    "ÂÅúÊ≠¢ÊêúÂØª", "ÂÅúÊ≠¢Âª∫Âõæ", "Êü•ËØ¢Êó∂Èó¥", "ÂÅúÊ≠¢ËßÅÂõæ", "ÂºÄÂßãÂØºËà™", "ÂÅúÊ≠¢ÂØºËà™"]
servers_dict = {"ÊêúÂØªÁõÆÊ†á" : "nav_semantic", 
                                "ÊûÑÂª∫ËØ≠‰πâÂú∞Âõæ" : "mapping_semantic", 
                                "ÊûÑÂª∫Âú∞Âõæ" : "mapping_semantic", 
                                "ÂºÄÂßãÂØºËà™" : "navigation", 
                                "ËøîÂõûÂéüÁÇπ" : "return_origin", 
                                "ËøîÂõûËµ∑ÁÇπ" : "return_origin", 
                                "ÂÅúÊ≠¢ÊêúÂØª" : "stop", 
                                "ÂÅúÊ≠¢ÂØºËà™" : "stop", 
                                "ÂÅúÊ≠¢Âª∫Âõæ" : "stop", 
                                "ÂÅúÊ≠¢ÈîÆÂõæ" : "stop", 
                                "ÂÅúÊ≠¢ËßÅÂõæ" : "stop", 
                                "Êü•ËØ¢Êó∂Èó¥" : ""}
# ÂëΩ‰ª§Êü•ËØ¢Â≠óÂÖ∏ AI-BoxÁ´Ø
cmds = {"mapping_semantic":"roslaunch xrobot aibox_mapping_and_semantic.launch", # ÊûÑÂª∫ËØ≠‰πâÂú∞Âõæ
                "navigation":"roslaunch xrobot aibox.launch", # Âú®Âú∞Âõæ‰∏≠ÂÆöÁÇπÂØºËà™
                "nav_semantic":"roslaunch xrobot aibox_nav_semantic.launch", # Âú®Âú∞Âõæ‰∏≠ËØ≠‰πâÊ†áÊ≥®
                "return_origin":"python /home/uzei/myrobot/src/xrobot/scripts/ReturnOrigin.py",
                "stop":"python3 /home/uzei/myrobot/src/xrobot/setup/aibox_end.py"} # ÂÅúÊ≠¢

def excu_server(svr):
    if svr in hero_cmds: # HERO
        send_cmd(svr)
        time.sleep(5)
    if svr in aibox_cmds: # AI-Box
        p = subprocess.Popen(cmds[svr], shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        for line in iter(p.stdout.readline, b''):
            print(line.decode())
        p.stdout.close()
        p.wait()
        if svr == "stop":
            # p.wait()
            SpeechSynthesis.speech_synthesis("Â∑≤ÂÅúÊ≠¢ÂÆåÊØïÔºåÂæàÈ´òÂÖ¥‰∏∫ÊÇ®ÊúçÂä°")


state = STATUS_WAITING_WAKE_UP
play_flag = False # Âú®ËøõË°åËØ≠Èü≥Êí≠Êä•Êó∂‰∏çËøõË°åÂÖ∂‰ªñÊìç‰ΩúÔºåÁõ∏ÂΩì‰∫é‰∏ÄÊääüîì

CHUNK = 8000
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
RECORD_SECONDS = 3
WAVE_OUTPUT_FILENAME = "output.wav"

p = pyaudio.PyAudio()
stream = p.open(format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK)

print("start recording")
last_index = 0
def si_thread(index, frame):
    ## ËØ≠Èü≥‰∫§‰∫íÁ∫øÁ®ã
    global state, play_flag, last_index
    
    # ËØ≠Èü≥ËØÜÂà´
    sr = SpeechRecognizer.SpeechRecognizer(frame) 
    sr.recognize()
    print(sr.ws.result)
    if play_flag == False and index > last_index:
        
        if state == STATUS_WAITING_WAKE_UP: # Â§Ñ‰∫éÁ≠âÂæÖÂî§ÈÜíÁä∂ÊÄÅ
            # if sr.ws.result == WAKE_UP_WORDS: # Âî§ÈÜíËØç
            if sr.ws.result in wake_up_words_list:
                last_index = index
                state = STATUS_WAITING_FOR_COMMAND
                play_flag = True
                SpeechSynthesis.speech_synthesis("ÂóØÔºå‰Ω†Â•ΩÔºåËØ∑ÈóÆÊÇ®Êúâ‰ªÄ‰πàÂê©Âíê")
                play_flag = False
        elif state == STATUS_WAITING_FOR_COMMAND: # Â§Ñ‰∫éÁ≠âÂæÖÂëΩ‰ª§Áä∂ÊÄÅ
            if sr.ws.result in servers:
                last_index = index
                state = STATUS_WORKING
                play_flag = True
                SpeechSynthesis.speech_synthesis("Â•ΩÁöÑÔºåÊ≠£Âú®" + sr.ws.result)
                play_flag = False
                
                state = STATUS_WAITING_WAKE_UP
                excu_server(servers_dict[sr.ws.result])

frames = []
cnt = 0
while True:
    if(state != STATUS_WORKING):
        # ËØªÂèñËØ≠Èü≥ÁöÑÂ≠óËäÇÊµÅ
        data = stream.read(CHUNK)
        frames.append(data)
        if len(frames) > RECORD_SECONDS * RATE / CHUNK:
            del frames[0]
        
        datas = b''
        for i in range(len(frames)):
            datas = datas + frames[i]

        if len(datas) == RECORD_SECONDS * RATE * 2:
            # Â≠óËäÇÊµÅËß£Á†Å
            fmt = "<" + str(RECORD_SECONDS * RATE) + "h"
            data_decode = np.array(st.unpack(fmt, bytes(datas)))
            # print("-------------")
            # ËØ≠Èü≥Á´ØÁÇπÊ£ÄÊµã
            isVoice, segments = VAD(data_decode, RATE)
            # print(isVoice)
            # Ê£ÄÊµãÂà∞Â£∞Èü≥ÔºåÂºÄÂêØ‰∏Ä‰∏™ËØ≠Èü≥‰∫§‰∫íÁ∫øÁ®ã
            if isVoice:
                cnt = cnt + 1
                if play_flag == False:
                    t = threading.Thread(target=si_thread, args=(cnt, frames))
                    t.start()

stream.stop_stream()
stream.close()
p.terminate()
print("stop recording")